import os
import time
import requests
from flask import Flask, request
from google import genai
from google.genai import types

# --- CONFIGURA√á√ïES ---
Z_API_ID = "3EC3280430DD02449072061BA788E473"
Z_API_TOKEN = "34E8E958D060C21D55F5A3D8"
CLIENT_TOKEN = "Ff1119996b44848dbaf394270f9933163S"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

app = Flask(__name__)
client = genai.Client(api_key=GEMINI_API_KEY)

# Mem√≥ria RAM para o hist√≥rico
chat_sessions = {}

# --- PROCESSO DE SONDAGEM R√çGIDO ---
PROMPT_SISTEMA = """
Voc√™ √© o Pedro Lima, consultor de expans√£o da Microlins. 
Seu objetivo √© qualificar o lead seguindo este roteiro de 5 perguntas.
IMPORTANTE: Analise o hist√≥rico. Se a informa√ß√£o j√° foi dada, N√ÉO repita a pergunta.

ROTEIRO:
1¬∫ (√ÅREA DE ATUA√á√ÉO) "Legal Sr, e me fala uma coisa, o Sr trabalha ou atua em qual √°rea a√≠ na sua cidade?"
2¬∫ (PRA√áA DE INTERESSE) "Ah legal, e me outra coisa, e o neg√≥cio pretende montar √© a√≠ na sua cidade mesmo?"
3¬∫ (PRAZO) "E esse neg√≥cio, voc√™ pretende abrir nos pr√≥ximos 3 meses ou √© algo mais a m√©dio ou longo prazo? E o que seria m√©dio ou longo prazo para o Sr?"
4¬∫ (LUCRO) "E me fala uma coisa Sr, esse neg√≥cio, pra ser bom para o Sr, ele precisa dar quanto na √∫ltima linha?"
5¬∫ (CAPITAL DISPON√çVEL) "Legal Sr, para voc√™ ter uma ideia, a lucratividade est√° diretamente ao investimento. Qual valor voc√™ tem dispon√≠vel para investir hoje?"

REGRAS:
- Uma pergunta por vez.
- Tom profissional, direto e humano.
"""

def gerar_resposta_ia(phone, mensagem_usuario):
    # MODELO ATUALIZADO DE 2025
    MODELO = "gemini-3-flash-preview" # Ou "gemini-3-flash" se j√° estiver em GA

    if phone not in chat_sessions:
        chat_sessions[phone] = []

    try:
        # Registra a fala do lead
        chat_sessions[phone].append({"role": "user", "content": mensagem_usuario})

        # Prepara o hist√≥rico estruturado para o Gemini 3
        contents = []
        for msg in chat_sessions[phone][-8:]: # √öltimas 8 intera√ß√µes
            contents.append(types.Content(role=msg["role"], parts=[types.Part.from_text(text=msg["content"])]))

        # Chamada da API com Instru√ß√£o de Sistema Nativa
        response = client.models.generate_content(
            model=MODELO,
            contents=contents,
            config=types.GenerateContentConfig(
                system_instruction=PROMPT_SISTEMA,
                temperature=0.7
            )
        )

        resposta_texto = response.text
        
        # Registra a resposta da IA no hist√≥rico
        chat_sessions[phone].append({"role": "model", "content": resposta_texto})
        
        return resposta_texto

    except Exception as e:
        print(f"‚ùå Erro na IA: {e}", flush=True)
        # Fallback simples caso a cota estoure
        return "Sr, tive uma pequena instabilidade no sistema. Poderia me confirmar em qual √°rea o Sr atua hoje?"

@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.json or {}
    if data.get("fromMe"): return "ok", 200

    msg = data.get("text", {}).get("message")
    phone = data.get("phone")

    if msg and phone:
        print(f"üì© Lead ({phone}): {msg}", flush=True)
        resp = gerar_resposta_ia(phone, msg)
        
        # Envio Z-API
        requests.post(
            f"https://api.z-api.io/instances/{Z_API_ID}/token/{Z_API_TOKEN}/send-text",
            json={"phone": phone, "message": resp}, 
            headers={"Client-Token": CLIENT_TOKEN, "Content-Type": "application/json"}
        )
        print(f"ü§ñ Bot: {resp}", flush=True)
            
    return "ok", 200

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host='0.0.0.0', port=port)
